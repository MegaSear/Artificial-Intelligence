{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from os.path import join as pjoin\nimport tqdm\nimport math\nimport pandas as pd\nimport numpy as np\nimport os\nimport torchvision\nimport time \nimport torch\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport sklearn\nfrom PIL import Image\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nimport gc\nimport cv2\nimport torchmetrics\nimport matplotlib.pyplot as plt\nfrom  torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\nfrom torchmetrics.classification import F1Score, Recall, Precision","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:02.381796Z","iopub.execute_input":"2023-04-23T20:43:02.382731Z","iopub.status.idle":"2023-04-23T20:43:02.390373Z","shell.execute_reply.started":"2023-04-23T20:43:02.382673Z","shell.execute_reply":"2023-04-23T20:43:02.389332Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"label_map = {\n             'abraham_grampa_simpson': 0,\n             'agnes_skinner': 1,\n             'apu_nahasapeemapetilon': 2,\n             'barney_gumble': 3,\n             'bart_simpson': 4,\n             'carl_carlson': 5,\n             'charles_montgomery_burns': 6,\n             'chief_wiggum': 7,\n             'cletus_spuckler': 8,\n             'comic_book_guy': 9,\n             'disco_stu': 10,\n             'edna_krabappel': 11,\n             'fat_tony': 12,\n             'gil': 13,\n             'groundskeeper_willie': 14,\n             'homer_simpson': 15,\n             'kent_brockman': 16,\n             'krusty_the_clown': 17,\n             'lenny_leonard': 18,\n             'lionel_hutz': 19,\n             'lisa_simpson': 20,\n             'maggie_simpson': 21,\n             'marge_simpson': 22,\n             'martin_prince': 23,\n             'mayor_quimby': 24,\n             'milhouse_van_houten': 25,\n             'miss_hoover': 26,\n             'moe_szyslak': 27,\n             'ned_flanders': 28,\n             'nelson_muntz': 29,\n             'otto_mann': 30,\n             'patty_bouvier': 31,\n             'principal_skinner': 32,\n             'professor_john_frink': 33,\n             'rainier_wolfcastle': 34,\n             'ralph_wiggum': 35,\n             'selma_bouvier': 36,\n             'sideshow_bob': 37,\n             'sideshow_mel': 38,\n             'snake_jailbird': 39,\n             'troy_mcclure': 40,\n             'waylon_smithers': 41\n             }","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:02.392464Z","iopub.execute_input":"2023-04-23T20:43:02.393179Z","iopub.status.idle":"2023-04-23T20:43:02.407210Z","shell.execute_reply.started":"2023-04-23T20:43:02.393138Z","shell.execute_reply":"2023-04-23T20:43:02.406121Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"code","source":"#Penalty\nfrom pathlib import Path\ndict_num_for_img = {}\nfull_n = 0\nfolder = \"/kaggle/input/simpson-norm/simpson/train\"\nfor name, i in label_map.items():\n    local_fold = Path(folder + \"/\" + name)\n    sum_img = sum(1 for x in local_fold.iterdir())\n    dict_num_for_img[name] = sum_img \n    full_n += sum_img\n\nclass_weight = []\nfor key, num in label_map.items():\n    class_weight.append(full_n/dict_num_for_img[key])\n\nweights = []\nfor i in range(len(class_weight)):\n    weights.append(math.log(sum(class_weight)/class_weight[i]))\n\nweights = torch.tensor(list(weights), dtype=torch.float)\nprint(weights)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:02.409804Z","iopub.execute_input":"2023-04-23T20:43:02.410842Z","iopub.status.idle":"2023-04-23T20:43:02.547980Z","shell.execute_reply.started":"2023-04-23T20:43:02.410810Z","shell.execute_reply":"2023-04-23T20:43:02.546600Z"},"trusted":true},"execution_count":209,"outputs":[{"name":"stdout","text":"tensor([6.5524, 3.4733, 6.1702, 4.3991, 6.9376, 4.3206, 6.8199, 6.6293, 3.5858,\n        5.8863, 2.1336, 5.8604, 3.0315, 3.0315, 4.5315, 7.4526, 5.9463, 6.8307,\n        5.4722, 1.6816, 6.9465, 4.5877, 6.8988, 3.9984, 5.2410, 6.7195, 2.5689,\n        7.0164, 7.0178, 5.6162, 3.2014, 4.0123, 6.8207, 3.9101, 3.5423, 4.2243,\n        4.3704, 6.5122, 3.4246, 3.7430, 1.8151, 4.9342])\n","output_type":"stream"}]},{"cell_type":"code","source":"learning_rate = 0.01#0.01\nweight_decay_adam = 0.005#0.005\nweight_decay = 0.005\nbatch_size = 128\nmomentum = 0.9\nnum_epochs = 100\ndrop_p = 0.25\nL2_enable = False\nL1_enable = False\nmean = [0.5881, 0.6786, 0.6122]\nstd = [0.2290, 0.2239, 0.2251]\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nweights = weights.to(device)\ncriterion = nn.CrossEntropyLoss(weight = weights, reduction='mean')","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:02.549746Z","iopub.execute_input":"2023-04-23T20:43:02.550247Z","iopub.status.idle":"2023-04-23T20:43:02.559136Z","shell.execute_reply.started":"2023-04-23T20:43:02.550204Z","shell.execute_reply":"2023-04-23T20:43:02.557783Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(degrees = 90),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n#ColorJitter\ndataset_train = torchvision.datasets.ImageFolder(root='/kaggle/input/simpson-norm/simpson/train', transform=transform)\ndataset_test  = torchvision.datasets.ImageFolder(root='/kaggle/input/simpson-norm/simpson/test' , transform=transform)\n\nnum_train = len(dataset_train)\nindices = list(range(num_train))\n\nsplit = int(np.floor(0.8 * num_train))\n\nnp.random.seed(np.random.randint(0, 10000))\nnp.random.shuffle(indices)\n\ntrain_idx, valid_idx = indices[:split], indices[split:]\n\ntrain_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_idx)\nvalid_sampler = torch.utils.data.sampler.SubsetRandomSampler(valid_idx)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:02.562642Z","iopub.execute_input":"2023-04-23T20:43:02.563042Z","iopub.status.idle":"2023-04-23T20:43:02.951306Z","shell.execute_reply.started":"2023-04-23T20:43:02.563002Z","shell.execute_reply":"2023-04-23T20:43:02.950207Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset_train, sampler = train_sampler, batch_size=batch_size, \n                                         num_workers=0, drop_last=True)\n\nvalid_loader = torch.utils.data.DataLoader(dataset_train, sampler = valid_sampler, batch_size=batch_size, \n                                         num_workers=0, drop_last=True)\n\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, \n                                         num_workers=0, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:02.954680Z","iopub.execute_input":"2023-04-23T20:43:02.955084Z","iopub.status.idle":"2023-04-23T20:43:02.963121Z","shell.execute_reply.started":"2023-04-23T20:43:02.955050Z","shell.execute_reply":"2023-04-23T20:43:02.961825Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"code","source":"class SimpsonsCNN(nn.Module):\n    def __init__(self):\n        super(SimpsonsCNN, self).__init__()\n\n        self.layer1 = nn.Sequential(nn.Conv2d( 3, 32, kernel_size=3, stride=1, padding=1), \n                                    nn.Dropout(drop_p), nn.BatchNorm2d(32), nn.ELU())\n        \n        self.layer2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.layer3 = nn.Sequential(nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1), \n                                    nn.Dropout(drop_p), nn.BatchNorm2d(32), nn.ELU(),\n                                    nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1), \n                                    nn.Dropout(drop_p), nn.BatchNorm2d(32), nn.ELU())\n        \n        self.layer4 = nn.MaxPool2d(kernel_size=2, stride=2) \n\n        self.layer5 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), \n                                    nn.Dropout(drop_p), nn.BatchNorm2d(64), nn.ELU())\n\n        self.layer6 = nn.MaxPool2d(kernel_size=2, stride=2) \n        \n        self.layer7 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), \n                                    nn.Dropout(drop_p), nn.BatchNorm2d(64), nn.ELU(),\n                                    nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), \n                                    nn.Dropout(drop_p), nn.BatchNorm2d(64), nn.ELU())\n        \n        self.layer8 = nn.MaxPool2d(kernel_size=2, stride=2)       \n        \n        self.layer9 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), \n                                    nn.Dropout(drop_p), nn.BatchNorm2d(128), nn.ELU())\n        \n        self.layer10 = nn.MaxPool2d(kernel_size=2, stride=2) \n        \n        self.layer11 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1), \n                                    nn.Dropout(drop_p), nn.BatchNorm2d(256), nn.ELU())\n        \n        self.layer12 = nn.MaxPool2d(kernel_size=2, stride=2) \n        \n        self.fc1 = nn.Linear( 1*16*256,1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear( 512,  42)\n        self.drop = nn.Dropout(drop_p)\n        \n    def forward(self, x):\n        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = x + self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = self.layer6(x)\n        x = x + self.layer7(x)\n        x = self.layer8(x)\n        x = self.layer9(x)\n        x = self.layer10(x)\n        x = self.layer11(x)\n        x = self.layer12(x)\n        \n        x = x.view(-1, 1*16*256)\n        x = F.elu(self.drop(self.fc1(x)))\n        x = F.elu(self.drop(self.fc2(x)))\n        x = self.fc3(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:02.965128Z","iopub.execute_input":"2023-04-23T20:43:02.966055Z","iopub.status.idle":"2023-04-23T20:43:02.984803Z","shell.execute_reply.started":"2023-04-23T20:43:02.966005Z","shell.execute_reply":"2023-04-23T20:43:02.983764Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef valid_map(model, loader):\n    classes = label_map\n    classes_amount = len(label_map)\n    recall = MulticlassRecall(num_classes=classes_amount, average=None)\n    precision = MulticlassPrecision(num_classes=classes_amount, average=None)\n    recall.to(device)\n    precision.to(device)\n    valid_acc = 0\n    with torch.no_grad():\n        my_loss = 0\n        model.eval()\n        correct = 0\n        total = 0\n        for sample in loader:\n            images, labels = sample[0], sample[1]\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            recall.update(outputs, labels)\n            precision.update(outputs, labels)\n            _, pred = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (pred == labels).sum().item()\n            my_loss += criterion(outputs, labels).item()\n        valid_acc = 100 * correct / total\n        avr_loss = my_loss/len(loader)\n    val_rec = sum(recall.compute())/len(list(label_map))\n    val_prec = sum(precision.compute())/len(list(label_map))\n    precision = val_prec.item()\n    recall = val_rec.item()\n    f1 = 2 * precision * recall / (precision + recall)\n    return avr_loss, valid_acc, recall, precision, f1","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:02.987851Z","iopub.execute_input":"2023-04-23T20:43:02.988294Z","iopub.status.idle":"2023-04-23T20:43:03.004306Z","shell.execute_reply.started":"2023-04-23T20:43:02.988233Z","shell.execute_reply":"2023-04-23T20:43:03.003240Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"code","source":"model = SimpsonsCNN()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:03.006309Z","iopub.execute_input":"2023-04-23T20:43:03.006789Z","iopub.status.idle":"2023-04-23T20:43:03.068305Z","shell.execute_reply.started":"2023-04-23T20:43:03.006744Z","shell.execute_reply":"2023-04-23T20:43:03.067285Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)\ncriterion = criterion.to(device)\nprint(count_parameters(model))","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:03.072292Z","iopub.execute_input":"2023-04-23T20:43:03.072592Z","iopub.status.idle":"2023-04-23T20:43:03.086887Z","shell.execute_reply.started":"2023-04-23T20:43:03.072564Z","shell.execute_reply":"2023-04-23T20:43:03.085800Z"},"trusted":true},"execution_count":216,"outputs":[{"name":"stdout","text":"5223786\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay = weight_decay_adam)\n#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum) \nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\nscaler = torch.cuda.amp.GradScaler()\ntorch.cuda.empty_cache()\ngc.collect()\nlist_train_loss = []\nlist_valid_loss = []","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:03.088554Z","iopub.execute_input":"2023-04-23T20:43:03.088909Z","iopub.status.idle":"2023-04-23T20:43:03.298647Z","shell.execute_reply.started":"2023-04-23T20:43:03.088874Z","shell.execute_reply":"2023-04-23T20:43:03.297502Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"code","source":"print(f'-------------------------------------Learning begin, total of {num_epochs} epochs-----------------------------------\\n')\nfor epoch in range(num_epochs):\n    correct, total = 0, 0\n\n    model.train()\n    for i, sample in enumerate(train_loader):\n        img, labels = sample[0], sample[1]\n        img = img.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n\n        with torch.cuda.amp.autocast(enabled=True):\n            output = model(img)\n            loss = criterion(output, labels)\n            _, pred = torch.max(output.data, 1)\n        \n        if L2_enable:\n            tens = (0.5 * weight_decay * sum(p.pow(2.0).sum() for p in model.parameters()))\n            l2_reg = (tens.clone().detach().to(device))\n            for name, param in model.named_parameters():\n                if 'weight' in name:\n                    l2_reg = l2_reg + torch.norm(param)\n            loss += weight_decay * l2_reg\n        \n        if L1_enable:\n            tens = (0.5 * weight_decay * sum(p.abs().sum() for p in model.parameters()))\n            l1_reg = (tens.clone().detach().to(device))\n            for name, param in model.named_parameters():\n                if 'weight' in name:\n                    l1_reg = l1_reg + torch.norm(param)\n            loss += weight_decay * l1_reg\n            \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n    \n        correct += (pred == labels).sum().item()\n        total += labels.size(0)\n        \n        if (i + 1) % 20 == 0:\n            train_acc = 100 * correct / total\n            correct, total = 0, 0\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], ', end = '')\n            print(f'Loss: {loss.item():.4f}, Acc: {train_acc:.2f}%')\n            list_train_loss.append(loss.item())\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n    avr_loss, val_acc, val_rec, val_prec, val_f1 = valid_map(model, valid_loader)\n    list_valid_loss.append(avr_loss)\n    print(f'\\n--------------------------------------------Result of Epoch {epoch}-------------------------------------------')\n    print(f'Valid_Loss: {avr_loss:.4f}, Valid_accuracy: {val_acc:.2f}%, Valid Recall: {100*val_rec:.2f}%, ', end = '')\n    print(f'Valid Precision: {100*val_prec:.2f}%, Valid F1: {100*val_f1:.2f}%')\n    print(f'---------------------------------------------------------------------------------------------------------\\n')\n        \n    if val_acc > 85:\n        break\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T20:43:03.300484Z","iopub.execute_input":"2023-04-23T20:43:03.301305Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"-------------------------------------Learning begin, total of 100 epochs-----------------------------------\n\nEpoch [1/100], Step [20/130], Loss: 8.0358, Acc: 5.98%\nEpoch [1/100], Step [40/130], Loss: 4.6945, Acc: 6.33%\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'-------------------------------------------Learning complete------------------------------------------\\n')\navr_loss, test_acc, test_rec, test_prec, test_f1 = valid_map(model, test_loader)\nprint(f'\\n--------------------------------------------Result of Testing-------------------------------------------')\nprint(f'Test_Loss: {avr_loss:.4f}, Test_accuracy: {test_acc:.2f}%, Test Recall: {100*test_rec:.2f}%, ', end = '')\nprint(f'Test Precision: {100*test_prec:.2f}%, Test F1: {100*test_f1:.2f}%')\nprint(f'---------------------------------------------------------------------------------------------------------\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = []\nfor name, param in model.named_parameters():\n    if 'weight' in name:\n        weights += param.data.cpu().numpy().flatten().tolist()\n\nweights = np.array(weights)\n\n# Построение гистограммы\nplt.hist(weights, bins=80, range = (-0.02, 0.02))\nplt.xlabel('Weight values')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.save(model.state_dict(), 'my_model.pt')\n#model.load_state_dict(torch.load('my_model.pt', map_location=device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\n\nplt.plot(list_train_loss, label='train')\nplt.plot(list_valid_loss, label='valid')\nplt.legend()\nplt.xlabel('Iterations')\nplt.ylabel('Loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loader = test_loader\nclasses = label_map\nclasses_amount = len(label_map)\nrecall = MulticlassRecall(num_classes=classes_amount, average=None)\nprecision = MulticlassPrecision(num_classes=classes_amount, average=None)\nrecall.to(device)\nprecision.to(device)\nvalid_acc = 0\nwith torch.no_grad():\n        my_loss = 0\n        model.eval()\n        correct = 0\n        total = 0\n        for sample in loader:\n            images, labels = sample[0], sample[1]\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            recall.update(outputs, labels)\n            precision.update(outputs, labels)\n            _, pred = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (pred == labels).sum().item()\n            my_loss += criterion(outputs, labels).item()\n        valid_acc = 100 * correct / total\n        avr_loss = my_loss/len(loader)\n        \nrecall_class = {classname: val.item()\n                for classname, val in zip(label_map, recall.compute())}\nprecision_class = {classname: val.item()\n                   for classname, val in zip(label_map,precision.compute())}\nmetrics_per_class = {\n    \"recall\": recall_class, \"precision\": precision_class}\n\nfig, axes = plt.subplots(1, 2, figsize=(25, 5))\nfor (metricName, mVal), ax in zip(metrics_per_class.items(), axes):\n    plt.sca(ax)\n    plt.bar(mVal.keys(), mVal.values())\n    plt.ylabel(metricName)\n    plt.xticks(rotation=90)\n    plt.grid(axis='y')\n    plt.yticks(ticks=np.arange(0, 1.01, 0.05))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = torchvision.models.resnet50(pretrained=True)\n#for param in model.parameters():\n#    param.requires_grad = False\n\n#model.fc = nn.Sequential(\n#    nn.Linear(1024, 128),\n#    nn.ReLU(inplace=True),\n#    nn.Linear(128, 42))\n\n#import time \n#start = time.time()\n#end = time.time()\n#print(end - start)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def batch_mean_and_std(loader):\n#    cnt = 0\n#    fst_moment = torch.empty(3)\n#    snd_moment = torch.empty(3)\n\n#    for images, _ in loader:\n#        b, c, h, w = images.shape\n#        nb_pixels = b * h * w\n#        sum_ = torch.sum(images, dim=[0, 2, 3])\n#        sum_of_square = torch.sum(images ** 2,\n#                                  dim=[0, 2, 3])\n#        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n#        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n#        cnt += nb_pixels\n\n#    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)        \n#    return mean,std\n  \n#mean, std = batch_mean_and_std(train_loader)\n#print(mean, std)\n#mean = [0.5881, 0.6786, 0.6122], std = [0.2290, 0.2239, 0.2251]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for name, layer in model.named_children():\n#    print(name, layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#path_for_test = 'simpson/archive_test'\n#names = []\n#for dirs, folder, files in os.walk(path_for_test):\n#     for img in files:\n#         ind = '_'.join(os.path.splitext(os.path.basename(path_for_test + '/' + img))[0].split('_')[:-1])\n#         names.append(ind)\n#names = list(set(names))\n#print(len(names))\n#folder_path = 'simpson'\n#os.mkdir(folder_path+'/test')\n#folder_path = folder_path + '/test'\n#for folder in names:\n#     if not os.path.exists(folder_path + '/' + folder):\n#         os.mkdir(folder_path + '/' + folder)\n#list_of_names = os.listdir(folder_path)\n#print(list_of_names)\n#for dirs, folder, files in os.walk(path_for_test):\n#     for img in files:\n#         ind = '_'.join(os.path.splitext(os.path.basename(path_for_test + '/' + img))[0].split('_')[:-1])\n#         for name in list_of_names:\n#             if ind == name:\n#                 shutil.move(path_for_test + '/' + img, folder_path + '/' + name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#n_classes = 42\n#class_counts = [0] * n_classes\n#for _, target in train_loader.dataset:\n#    class_counts[target] += 1\n#n_samples = len(train_loader.dataset)\n#weights = torch.tensor([n_samples / (n_classes * class_counts[i]) for i in range(n_classes)], dtype=torch.float)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
