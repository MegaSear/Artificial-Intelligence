{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7f9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import torchmetrics\n",
    "import torchinfo\n",
    "import matplotlib.pyplot as plt\n",
    "from  torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2707ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "             'abraham_grampa_simpson': 0,\n",
    "             'agnes_skinner': 1,\n",
    "             'apu_nahasapeemapetilon': 2,\n",
    "             'barney_gumble': 3,\n",
    "             'bart_simpson': 4,\n",
    "             'carl_carlson': 5,\n",
    "             'charles_montgomery_burns': 6,\n",
    "             'chief_wiggum': 7,\n",
    "             'cletus_spuckler': 8,\n",
    "             'comic_book_guy': 9,\n",
    "             'disco_stu': 10,\n",
    "             'edna_krabappel': 11,\n",
    "             'fat_tony': 12,\n",
    "             'gil': 13,\n",
    "             'groundskeeper_willie': 14,\n",
    "             'homer_simpson': 15,\n",
    "             'kent_brockman': 16,\n",
    "             'krusty_the_clown': 17,\n",
    "             'lenny_leonard': 18,\n",
    "             'lionel_hutz': 19,\n",
    "             'lisa_simpson': 20,\n",
    "             'maggie_simpson': 21,\n",
    "             'marge_simpson': 22,\n",
    "             'martin_prince': 23,\n",
    "             'mayor_quimby': 24,\n",
    "             'milhouse_van_houten': 25,\n",
    "             'miss_hoover': 26,\n",
    "             'moe_szyslak': 27,\n",
    "             'ned_flanders': 28,\n",
    "             'nelson_muntz': 29,\n",
    "             'otto_mann': 30,\n",
    "             'patty_bouvier': 31,\n",
    "             'principal_skinner': 32,\n",
    "             'professor_john_frink': 33,\n",
    "             'rainier_wolfcastle': 34,\n",
    "             'ralph_wiggum': 35,\n",
    "             'selma_bouvier': 36,\n",
    "             'sideshow_bob': 37,\n",
    "             'sideshow_mel': 38,\n",
    "             'snake_jailbird': 39,\n",
    "             'troy_mcclure': 40,\n",
    "             'waylon_smithers': 41\n",
    "             }\n",
    "\n",
    "class Simpson_Train_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, annotations_file, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.bboxes = []\n",
    "        self.labels = []\n",
    "        with open(annotations_file, 'r') as f:\n",
    "            for line in f:\n",
    "                image_path, x1, y1, x2, y2, label = line.strip().split(',')\n",
    "                if os.path.exists(image_path):\n",
    "                    self.image_paths.append(image_path)\n",
    "                    self.bboxes.append([int(x1), int(y1), int(x2), int(y2)])\n",
    "                    self.labels.append(label)\n",
    "                    self.bbox = torch.tensor(self.bboxes)\n",
    "                #else:\n",
    "                    #print('Не существует файла. Путь:', image_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "        bbox = self.bboxes[index]\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = label_map[self.labels[index]]\n",
    "        return image, label, bbox\n",
    "\n",
    "\n",
    "class Simpson_Test_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_folder, transform=None):\n",
    "        self.image_paths = []\n",
    "        for image_filename in os.listdir(data_folder):\n",
    "            if os.path.isfile(os.path.join(data_folder, image_filename)):\n",
    "                self.image_paths.append(os.path.join(data_folder, image_filename))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = os.path.basename(image_path)\n",
    "        label = '_'.join(label.split('_')[:-1])\n",
    "        label = label_map[label]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3c2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees = 90),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "data_set = Simpson_Train_Dataset('annotation.txt', transform=train_transform)\n",
    "test_data = Simpson_Test_Dataset('test', transform=test_transform)\n",
    "\n",
    "train_data, val_data = train_test_split(data_set, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec65a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size, \n",
    "                                         num_workers=0, drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=True, batch_size=batch_size, \n",
    "                                         num_workers=0, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, batch_size=batch_size, \n",
    "                                           num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388ba07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpsonsCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpsonsCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential( nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.BatchNorm2d(4), nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2),  \n",
    "                                    nn.Conv2d(4, 16, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "                                    nn.Dropout(0.25))\n",
    "        \n",
    "        self.conv2 = nn.Sequential( nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.BatchNorm2d(32), nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "                                    nn.Dropout(0.25))\n",
    "        \n",
    "        self.conv3 = nn.Sequential( nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "                                    nn.Dropout(0.25))\n",
    "        \n",
    "        self.conv4 = nn.Sequential( nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.BatchNorm2d(256), nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "                                    nn.Dropout(0.25))\n",
    "\n",
    "        self.AApool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(128 * int(128 / batch_size), 1024)\n",
    "        self.fc2 = nn.Linear(1024, 42)\n",
    "        self.Mpool = nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(-1, 128 * int(128 / batch_size))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = SimpsonsCNN()\n",
    "print(count_parameters(model))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c300243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41212554\n"
     ]
    }
   ],
   "source": [
    "def valid_map(loader):\n",
    "    classes = label_map\n",
    "    classes_amount = len(label_map)\n",
    "    recall = MulticlassRecall(num_classes=classes_amount, average=None)\n",
    "    precision = MulticlassPrecision(num_classes=classes_amount, average=None)\n",
    "    recall.to(device)\n",
    "    precision.to(device)\n",
    "    valid_acc = 0\n",
    "    N = 0\n",
    "    with torch.no_grad():\n",
    "        my_loss = 0\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for sample in loader:\n",
    "            images = sample[0]\n",
    "            labels = sample[1]\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            recall.update(outputs, labels)\n",
    "            precision.update(outputs, labels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            tens = (0.5 * weight_decay * sum(p.pow(2.0).sum() for p in model.parameters()))\n",
    "            my_l2_reg = (tens.clone().detach().to(device))\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    my_l2_reg = my_l2_reg + torch.norm(param)\n",
    "            my_loss += weight_decay * my_l2_reg\n",
    "            my_loss += criterion(outputs, labels).item()\n",
    "            N += 1\n",
    "        valid_acc = 100 * correct / total\n",
    "        avr_loss = my_loss/N\n",
    "    \n",
    "    return avr_loss, valid_acc, recall, precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef63139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\searg\\AppData\\Local\\Temp\\ipykernel_14352\\8910251.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  l2_reg = torch.tensor(0.5 * weight_decay * sum(p.pow(2.0).sum() for p in model.parameters())).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/74], Loss: 10.3681\n",
      "Epoch [1/10], Step [20/74], Loss: 3.7934\n",
      "Epoch [1/10], Step [30/74], Loss: 4.2997\n",
      "Epoch [1/10], Step [40/74], Loss: 3.4442\n",
      "Epoch [1/10], Step [50/74], Loss: 3.1922\n",
      "Epoch [1/10], Step [60/74], Loss: 3.2022\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m         l2_reg \u001b[39m=\u001b[39m l2_reg \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mnorm(param)\n\u001b[0;32m     20\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m weight_decay \u001b[39m*\u001b[39m l2_reg\n\u001b[1;32m---> 22\u001b[0m scaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     23\u001b[0m scaler\u001b[39m.\u001b[39mstep(optimizer)\n\u001b[0;32m     24\u001b[0m scaler\u001b[39m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\searg\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\searg\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "#momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "#optimizer = torch.optim.SGD( model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay = weight_decay)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "num_epochs = 1000\n",
    "print(f'-----------------------------Learning begin, total of {num_epochs} epochs----------------------------\\n')\n",
    "for epoch in range(num_epochs):\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    avr_loss, val_acc, val_rec, val_prec = valid_map(val_loader)\n",
    "    val_rec = sum(val_rec.compute())/len(list(label_map))\n",
    "    val_prec = sum(val_prec.compute())/len(list(label_map))\n",
    "    print(f'\\n-------------------------------------Result of Epoch {epoch}------------------------------------')\n",
    "    print(f'Valid_Loss: {avr_loss:.4f}, Valid_accuracy: {val_acc:.2f}%, Valid Recall: {100*val_rec.item():.2f}%, Valid Precision: {100*val_prec.item():.2f}%')\n",
    "    print(f'-------------------------------------------------------------------------------------------\\n')\n",
    "    if val_acc > 85:\n",
    "        break\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    for i, (img, labels, _) in enumerate(train_loader):\n",
    "        img = img.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            pred = model(img)\n",
    "            loss = criterion(pred, labels)\n",
    "            _, pred1 = torch.max(pred.data, 1)\n",
    "        \n",
    "        #tens = (0.5 * weight_decay * sum(p.pow(2.0).sum() for p in model.parameters()))\n",
    "        #l2_reg = (tens.clone().detach().to(device))\n",
    "        \n",
    "        #for name, param in model.named_parameters():\n",
    "        #    if 'weight' in name:\n",
    "        #        l2_reg = l2_reg + torch.norm(param)\n",
    "\n",
    "        #loss += weight_decay * l2_reg\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        correct += (pred1 == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            train_acc = 100 * correct / total\n",
    "            correct, total = 0, 0\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Acc: {train_acc:.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'------------------------------------Learning complete-----------------------------------\\n')\n",
    "avr_loss, test_acc, test_rec, test_prec = valid_map(test_loader)\n",
    "rec = sum(test_rec.compute())/len(list(label_map))\n",
    "prec = sum(test_prec.compute())/len(list(label_map))\n",
    "print(f'\\n-------------------------------------Result of Testing------------------------------------')\n",
    "print(f'Valid_Loss: {avr_loss:.4f}, Valid_accuracy: {test_acc:.2f}%, Valid Recall: {rec.item():.2f}%, Valid Precision: {prec.item():.2f}%')\n",
    "print(f'-------------------------------------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b012a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1: 0.0879\n"
     ]
    }
   ],
   "source": [
    "recall_class = {classname: val.item()\n",
    "                for classname, val in zip(label_map, test_rec.compute())}\n",
    "precision_class = {classname: val.item()\n",
    "                   for classname, val in zip(label_map, test_prec.compute())}\n",
    "metrics_per_class = {\n",
    "    \"recall\": recall_class, \"precision\": precision_class}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(25, 5))\n",
    "for (metricName, mVal), ax in zip(metrics_per_class.items(), axes):\n",
    "    plt.sca(ax)\n",
    "    plt.bar(mVal.keys(), mVal.values())\n",
    "    plt.ylabel(metricName)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(axis='y')\n",
    "    plt.yticks(ticks=np.arange(0, 1.01, 0.05))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
